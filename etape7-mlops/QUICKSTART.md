# ðŸš€ Guide de DÃ©marrage Rapide - MLOps avec Vertex AI

## ðŸ“‹ Vue d'ensemble

Ce dossier contient le pipeline MLOps complet pour automatiser l'entraÃ®nement et le dÃ©ploiement du modÃ¨le de dÃ©tection de toxicitÃ©.

### Architecture du pipeline

```
1. PrÃ©paration donnÃ©es â†’ 2. EntraÃ®nement â†’ 3. Ã‰valuation â†’ 4. DÃ©ploiement
        â†“                      â†“                  â†“              â†“
   Anonymisation          BERT/Simple        F1-Score       Si F1 > 0.75
   Nettoyage             Fine-tuning         Accuracy       â†’ Deploy auto
```

---

## âš¡ DÃ©marrage rapide (5 minutes)

### 1. Installer les dÃ©pendances

```bash
cd etape7-mlops
pip install -r requirements.txt
```

### 2. Activer les APIs nÃ©cessaires

```bash
python setup_vertex_ai.py
```

### 3. Uploader les donnÃ©es d'entraÃ®nement

```bash
python upload_training_data.py
```

### 4. Compiler le pipeline

```bash
python compile_pipeline.py
```

### 5. Lancer le pipeline

```bash
python trigger_pipeline.py --model-type simple
```

---

## ðŸ“‚ Structure des fichiers

```
etape7-mlops/
â”œâ”€â”€ vertex_pipelines/
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ prepare_data.py          # Composant de prÃ©paration des donnÃ©es
â”‚   â”‚   â”œâ”€â”€ train_model.py           # Composant d'entraÃ®nement
â”‚   â”‚   â””â”€â”€ evaluate_model.py        # Composant d'Ã©valuation
â”‚   â”œâ”€â”€ pipeline_definition.py       # DÃ©finition du pipeline complet
â”‚   â””â”€â”€ ml_pipeline.json             # Pipeline compilÃ© (gÃ©nÃ©rÃ©)
â”œâ”€â”€ compile_pipeline.py              # Script de compilation
â”œâ”€â”€ trigger_pipeline.py              # Script de dÃ©clenchement
â”œâ”€â”€ upload_training_data.py          # Upload donnÃ©es vers GCS
â”œâ”€â”€ setup_vertex_ai.py               # Configuration initiale
â”œâ”€â”€ requirements.txt                 # DÃ©pendances Python
â””â”€â”€ README.md                        # Ce fichier
```

---

## ðŸ”§ Configuration

### Variables d'environnement

Le pipeline utilise ces configurations par dÃ©faut :

```python
PROJECT_ID = "digitalsocialscoreapi"
REGION = "europe-west1"
PIPELINE_ROOT = "gs://digitalsocialscoreapi_cloudbuild/vertex-pipelines"
```

### ParamÃ¨tres du pipeline

Vous pouvez personnaliser l'entraÃ®nement :

```bash
# ModÃ¨le simple (rapide, ~5-10 min)
python trigger_pipeline.py --model-type simple

# ModÃ¨le BERT (lent, ~30-60 min, meilleure performance)
python trigger_pipeline.py --model-type bert
```

---

## ðŸ“Š Suivre l'exÃ©cution

Une fois le pipeline lancÃ©, vous pouvez suivre son exÃ©cution :

**Console Vertex AI :**
https://console.cloud.google.com/vertex-ai/pipelines

**Logs Cloud Logging :**
https://console.cloud.google.com/logs

---

## ðŸ”„ IntÃ©gration avec Cloud Build

Le pipeline peut Ãªtre dÃ©clenchÃ© automatiquement par Cloud Build.

### Option 1 : DÃ©clenchement manuel

Ajoutez dans `cloudbuild.yaml` :

```yaml
# Ã‰tape optionnelle : Lancer le pipeline MLOps
- name: 'python:3.10-slim'
  id: 'trigger-ml-pipeline'
  entrypoint: 'bash'
  args:
    - '-c'
    - |
      pip install -q kfp google-cloud-aiplatform
      python etape7-mlops/trigger_pipeline.py --model-type simple
  waitFor: ['smoke-tests']
```

### Option 2 : DÃ©clenchement hebdomadaire

CrÃ©ez un Cloud Scheduler qui lance le pipeline chaque semaine :

```bash
gcloud scheduler jobs create http ml-pipeline-weekly \
  --location=europe-west1 \
  --schedule="0 2 * * 0" \
  --uri="https://europe-west1-aiplatform.googleapis.com/v1/projects/digitalsocialscoreapi/locations/europe-west1/pipelineJobs" \
  --message-body-from-file=pipeline_trigger.json
```

---

## ðŸ§ª Tests

### Tester la compilation

```bash
python compile_pipeline.py
# VÃ©rifie que vertex_pipelines/ml_pipeline.json est crÃ©Ã©
```

### Tester l'upload des donnÃ©es

```bash
python upload_training_data.py --dry-run
```

### Tester un composant individuellement

```bash
cd vertex_pipelines/components
python prepare_data.py  # Test local
```

---

## ðŸ“ˆ Monitoring

Le pipeline gÃ©nÃ¨re des mÃ©triques Ã  chaque exÃ©cution :

- **F1-Score** : Performance du modÃ¨le
- **Accuracy** : PrÃ©cision globale
- **Temps d'entraÃ®nement** : DurÃ©e totale
- **Taille du modÃ¨le** : Espace disque

Ces mÃ©triques sont stockÃ©es dans :
- Vertex AI Metadata Store
- GCS : `gs://digitalsocialscoreapi_cloudbuild/vertex-pipelines/metrics/`

---

## ðŸš¨ Troubleshooting

### Erreur : "Permission denied"

Assurez-vous que le compte de service a les permissions :

```bash
gcloud projects add-iam-policy-binding digitalsocialscoreapi \
  --member="serviceAccount:YOUR_SA@digitalsocialscoreapi.iam.gserviceaccount.com" \
  --role="roles/aiplatform.user"
```

### Erreur : "Bucket not found"

CrÃ©ez le bucket GCS :

```bash
gsutil mb -l europe-west1 gs://digitalsocialscoreapi_cloudbuild
```

### Pipeline Ã©choue Ã  l'entraÃ®nement

VÃ©rifiez les logs dÃ©taillÃ©s dans Vertex AI :

```bash
gcloud ai custom-jobs describe JOB_ID \
  --region=europe-west1 \
  --project=digitalsocialscoreapi
```

---

## ðŸ“š Ressources

- [Vertex AI Pipelines Documentation](https://cloud.google.com/vertex-ai/docs/pipelines)
- [Kubeflow Pipelines SDK](https://www.kubeflow.org/docs/components/pipelines/)
- [MLOps Best Practices](https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning)

---

## ðŸŽ¯ Prochaines Ã©tapes

1. âœ… Pipeline de base fonctionnel
2. ðŸ”„ Ajout du monitoring en production
3. ðŸ”„ A/B testing entre modÃ¨les
4. ðŸ”„ DÃ©tection de drift des donnÃ©es
5. ðŸ”„ RÃ©entraÃ®nement automatique conditionnel

---

**Date de crÃ©ation :** 8 novembre 2025  
**Version :** 1.0  
**Auteur :** Digital Social Score Team
