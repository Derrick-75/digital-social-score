"""
Pipeline Vertex AI : MLOps Digital Social Score
Pipeline complet d'entra√Ænement et d√©ploiement automatique
"""

from kfp.v2 import dsl
from kfp.v2.dsl import pipeline
from google.cloud import aiplatform

# Import des composants
from .components.prepare_data import prepare_data_op
from .components.train_model import train_model_op
from .components.evaluate_model import evaluate_and_decide_op


@pipeline(
    name="digital-social-score-ml-pipeline",
    description="Pipeline MLOps pour entra√Æner et d√©ployer le mod√®le de d√©tection de toxicit√©",
    pipeline_root="gs://digitalsocialscoreapi-mlops/vertex-pipelines"
)
def ml_pipeline(
    # Param√®tres du pipeline
    raw_data_gcs_path: str = "gs://digitalsocialscoreapi_cloudbuild/data/train.csv",
    test_data_gcs_path: str = "gs://digitalsocialscoreapi_cloudbuild/data/test.csv",
    model_type: str = "simple",  # "simple" ou "bert"
    epochs: int = 3,
    batch_size: int = 16,
    learning_rate: float = 2e-5,
    min_f1_threshold: float = 0.75,
    project_id: str = "digitalsocialscoreapi",
    region: str = "europe-west1"
):
    """
    Pipeline ML complet pour Digital Social Score
    
    √âtapes:
    1. Pr√©paration des donn√©es (nettoyage + anonymisation)
    2. Entra√Ænement du mod√®le (BERT ou Simple)
    3. √âvaluation sur dataset de test
    4. D√©cision de d√©ploiement bas√©e sur F1-score
    5. D√©ploiement automatique si performances suffisantes
    
    Args:
        raw_data_gcs_path: Chemin GCS des donn√©es brutes d'entra√Ænement
        test_data_gcs_path: Chemin GCS des donn√©es de test
        model_type: Type de mod√®le ("simple" ou "bert")
        epochs: Nombre d'√©poques d'entra√Ænement
        batch_size: Taille des batches
        learning_rate: Taux d'apprentissage
        min_f1_threshold: Seuil F1 minimum pour d√©ployer
        project_id: ID du projet GCP
        region: R√©gion GCP
    """
    
    # ========================================
    # √âTAPE 1 : Pr√©paration des donn√©es
    # ========================================
    prepare_data_task = prepare_data_op(
        raw_data_gcs_path=raw_data_gcs_path
    )
    prepare_data_task.set_display_name("üìã Pr√©paration des donn√©es")
    prepare_data_task.set_cpu_limit('2')
    prepare_data_task.set_memory_limit('4G')
    
    # ========================================
    # √âTAPE 2 : Entra√Ænement du mod√®le
    # ========================================
    train_model_task = train_model_op(
        training_data=prepare_data_task.outputs['anonymized_data'],
        epochs=epochs,
        batch_size=batch_size,
        learning_rate=learning_rate
    )
    train_model_task.set_display_name("ü§ñ Entra√Ænement mod√®le")
    train_model_task.set_cpu_limit('4')
    train_model_task.set_memory_limit('8G')
    
    # Note: Le mod√®le type est BERT (cod√© en dur dans le composant)
    
    # ========================================
    # √âTAPE 3 : √âvaluation du mod√®le
    # ========================================
    evaluate_model_task = evaluate_and_decide_op(
        test_data_gcs_path=test_data_gcs_path,
        new_model=train_model_task.outputs['model_output'],
        current_model_f1=0.5,  # F1-Score baseline (√† ajuster selon votre mod√®le actuel)
        improvement_threshold=0.02
    )
    evaluate_model_task.set_display_name("üìä √âvaluation du mod√®le")
    evaluate_model_task.set_cpu_limit('2')
    evaluate_model_task.set_memory_limit('4G')
    
    # ========================================
    # √âTAPE 4 : D√©ploiement conditionnel
    # ========================================
    # Le d√©ploiement se fera si should_deploy == True
    # Cette logique peut √™tre ajout√©e avec une condition dsl
    
    with dsl.Condition(
        evaluate_model_task.outputs['should_deploy'] == True,
        name="deploy-if-good-performance"
    ):
        # Ici on pourrait ajouter un composant de d√©ploiement
        # qui met √† jour l'API avec le nouveau mod√®le
        
        @dsl.component(
            base_image="python:3.10-slim",
            packages_to_install=["google-cloud-storage==2.10.0"]
        )
        def deploy_model_component(
            trained_model: dsl.Input[dsl.Model],
            f1_score: float,
            project_id: str,
            destination_bucket: str = "digitalsocialscoreapi_cloudbuild"
        ):
            """
            D√©ploie le nouveau mod√®le vers GCS
            """
            from google.cloud import storage
            import json
            from datetime import datetime
            
            print(f"üöÄ D√©ploiement du nouveau mod√®le (F1={f1_score:.4f})...")
            
            # Upload vers GCS
            client = storage.Client(project=project_id)
            bucket = client.bucket(destination_bucket)
            
            # Nom avec timestamp
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            model_path = f"models/deployed/model_{timestamp}"
            
            # Upload des fichiers du mod√®le
            import os
            for root, dirs, files in os.walk(trained_model.path):
                for file in files:
                    local_path = os.path.join(root, file)
                    relative_path = os.path.relpath(local_path, trained_model.path)
                    blob_path = f"{model_path}/{relative_path}"
                    
                    blob = bucket.blob(blob_path)
                    blob.upload_from_filename(local_path)
                    print(f"  ‚úÖ Uploaded: {blob_path}")
            
            # Marquer comme mod√®le actif
            active_model_blob = bucket.blob("models/active_model.json")
            active_model_blob.upload_from_string(
                json.dumps({
                    "model_path": model_path,
                    "f1_score": f1_score,
                    "deployed_at": timestamp
                })
            )
            
            print(f"‚úÖ Mod√®le d√©ploy√© avec succ√®s vers gs://{destination_bucket}/{model_path}")
        
        deploy_task = deploy_model_component(
            trained_model=train_model_task.outputs['model_output'],
            f1_score=evaluate_model_task.outputs['new_f1_score'],
            project_id=project_id
        )
        deploy_task.set_display_name("üöÄ D√©ploiement du mod√®le")


# ========================================
# Fonction de compilation du pipeline
# ========================================
def compile_pipeline(output_file: str = "ml_pipeline.json"):
    """
    Compile le pipeline en fichier JSON
    """
    from kfp.v2 import compiler
    
    compiler.Compiler().compile(
        pipeline_func=ml_pipeline,
        package_path=output_file
    )
    
    print(f"‚úÖ Pipeline compil√©: {output_file}")


if __name__ == "__main__":
    # Compilation du pipeline
    compile_pipeline()
