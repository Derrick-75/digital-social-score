# √âtape 7 : MLOps avec Vertex AI Pipelines

## üéØ Objectif

Automatiser compl√®tement le cycle de vie du mod√®le ML :
- ‚úÖ Pr√©paration automatique des donn√©es
- ‚úÖ Entra√Ænement automatis√© (BERT ou Simple)
- ‚úÖ √âvaluation et validation
- ‚úÖ D√©ploiement conditionnel bas√© sur les performances

## üèóÔ∏è Architecture du Pipeline

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  1. Pr√©paration     ‚îÇ
‚îÇ     des donn√©es     ‚îÇ
‚îÇ  - Nettoyage        ‚îÇ
‚îÇ  - Anonymisation    ‚îÇ
‚îÇ  - Statistiques     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ
           ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  2. Entra√Ænement    ‚îÇ
‚îÇ     du mod√®le       ‚îÇ
‚îÇ  - BERT ou Simple   ‚îÇ
‚îÇ  - Hyperparam√®tres  ‚îÇ
‚îÇ  - Sauvegarde       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ
           ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  3. √âvaluation      ‚îÇ
‚îÇ  - M√©triques (F1)   ‚îÇ
‚îÇ  - Validation       ‚îÇ
‚îÇ  - D√©cision deploy  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ
           ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  4. D√©ploiement     ‚îÇ
‚îÇ     (conditionnel)  ‚îÇ
‚îÇ  - Si F1 >= 0.75    ‚îÇ
‚îÇ  - Upload GCS       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üìÅ Structure des fichiers

```
etape7-mlops/
‚îú‚îÄ‚îÄ requirements.txt                    # D√©pendances MLOps
‚îú‚îÄ‚îÄ README.md                          # Cette documentation
‚îî‚îÄ‚îÄ vertex_pipelines/
    ‚îú‚îÄ‚îÄ components/                    # Composants KFP
    ‚îÇ   ‚îú‚îÄ‚îÄ prepare_data.py           # Pr√©paration des donn√©es
    ‚îÇ   ‚îú‚îÄ‚îÄ train_model.py            # Entra√Ænement du mod√®le
    ‚îÇ   ‚îî‚îÄ‚îÄ evaluate_model.py         # √âvaluation du mod√®le
    ‚îú‚îÄ‚îÄ pipeline_definition.py         # D√©finition du pipeline complet
    ‚îî‚îÄ‚îÄ trigger_pipeline.py            # Script de d√©clenchement
```

## üöÄ Utilisation

### 1. Pr√©requis

```bash
# Installer les d√©pendances
pip install -r requirements.txt

# Activer l'API Vertex AI
gcloud services enable aiplatform.googleapis.com

# Cr√©er un bucket GCS pour les artefacts (si pas d√©j√† fait)
gsutil mb -l europe-west1 gs://digitalsocialscoreapi_cloudbuild
```

### 2. Uploader les donn√©es d'entra√Ænement sur GCS

```bash
# Copier les datasets vers GCS
gsutil cp etape1-anonymisation/data/raw/train_advanced.csv \
    gs://digitalsocialscoreapi_cloudbuild/data/

gsutil cp etape1-anonymisation/data/raw/test_advanced.csv \
    gs://digitalsocialscoreapi_cloudbuild/data/
```

### 3. D√©clencher manuellement le pipeline

```bash
cd etape7-mlops/vertex_pipelines

# Entra√Æner un mod√®le simple
python trigger_pipeline.py \
    --project-id digitalsocialscoreapi \
    --region europe-west1 \
    --model-type simple \
    --epochs 3

# Entra√Æner un mod√®le BERT
python trigger_pipeline.py \
    --project-id digitalsocialscoreapi \
    --region europe-west1 \
    --model-type bert \
    --epochs 5
```

### 4. Int√©gration avec Cloud Build (Automatique)

Le pipeline sera automatiquement d√©clench√© apr√®s chaque d√©ploiement r√©ussi via Cloud Build.

**Ajout dans `cloudbuild.yaml` :**

```yaml
# √âtape 7 : D√©clencher le pipeline MLOps (optionnel)
- name: 'gcr.io/google.com/cloudsdktool/cloud-sdk:slim'
  id: 'trigger-mlops-pipeline'
  entrypoint: 'bash'
  waitFor: ['smoke-tests']
  args:
    - '-c'
    - |
      pip install -r etape7-mlops/requirements.txt
      cd etape7-mlops/vertex_pipelines
      python trigger_pipeline.py \
        --project-id $PROJECT_ID \
        --region europe-west1 \
        --model-type simple \
        --epochs 3
```

## üìä Monitoring du Pipeline

### Console Vertex AI

1. Ouvrir : https://console.cloud.google.com/vertex-ai/pipelines/runs?project=digitalsocialscoreapi
2. S√©lectionner votre pipeline run
3. Visualiser :
   - ‚úÖ √âtat de chaque √©tape
   - üìà M√©triques d'entra√Ænement
   - üìä R√©sultats d'√©valuation
   - üöÄ D√©cision de d√©ploiement

### Logs Cloud Logging

```bash
# Voir les logs du pipeline
gcloud logging read "resource.type=ml_job" --limit 50 --format json
```

## üîß Configuration des Param√®tres

Le pipeline accepte plusieurs param√®tres configurables :

| Param√®tre | Description | D√©faut |
|-----------|-------------|--------|
| `raw_data_gcs_path` | Chemin GCS des donn√©es d'entra√Ænement | `gs://.../train_advanced.csv` |
| `test_data_gcs_path` | Chemin GCS des donn√©es de test | `gs://.../test_advanced.csv` |
| `model_type` | Type de mod√®le (`simple` ou `bert`) | `simple` |
| `epochs` | Nombre d'√©poques d'entra√Ænement | `3` |
| `batch_size` | Taille des batches | `16` |
| `learning_rate` | Taux d'apprentissage | `2e-5` |
| `min_f1_threshold` | Seuil F1 pour d√©ployer | `0.75` |

**Modifier dans `trigger_pipeline.py` :**

```python
pipeline_parameters = {
    "epochs": 10,           # Plus d'√©poques
    "batch_size": 32,       # Batches plus grands
    "min_f1_threshold": 0.80  # Seuil plus √©lev√©
}
```

## üéì Composants du Pipeline

### 1. `prepare_data_component`

**Fonction :** Nettoie et anonymise les donn√©es

**Inputs :**
- `raw_data_path` : Chemin vers les donn√©es brutes (CSV)

**Outputs :**
- `output_dataset` : Dataset nettoy√© et anonymis√©

**Actions :**
- Suppression des doublons
- Gestion des valeurs manquantes
- Anonymisation des emails (SHA-256)
- Calcul des statistiques

### 2. `train_model_component`

**Fonction :** Entra√Æne le mod√®le ML

**Inputs :**
- `input_dataset` : Dataset pr√©par√©
- `model_type` : Type de mod√®le ("simple" ou "bert")
- `epochs`, `batch_size`, `learning_rate`

**Outputs :**
- `output_model` : Mod√®le entra√Æn√©

**Mod√®les support√©s :**
- **Simple :** TF-IDF + Logistic Regression
- **BERT :** BERT fine-tuned sur les donn√©es

### 3. `evaluate_model_component`

**Fonction :** √âvalue les performances du mod√®le

**Inputs :**
- `test_dataset` : Dataset de test
- `trained_model` : Mod√®le entra√Æn√©
- `min_f1_threshold` : Seuil F1 minimum

**Outputs :**
- `f1_score` : Score F1 obtenu
- `should_deploy` : Boolean (d√©ployer ou non)

**M√©triques calcul√©es :**
- Accuracy, Precision, Recall, F1-Score
- AUC-ROC
- Matrice de confusion

### 4. `deploy_model_component`

**Fonction :** D√©ploie le mod√®le si performances suffisantes

**Condition :** `should_deploy == True` (F1 >= threshold)

**Actions :**
- Upload du mod√®le vers GCS
- Mise √† jour du pointeur `active_model.json`
- Versioning avec timestamp

## üìà M√©triques de R√©f√©rence

| Mod√®le | F1-Score | Pr√©cision | Rappel | AUC-ROC |
|--------|----------|-----------|--------|---------|
| Simple (baseline) | 0.75+ | 0.73+ | 0.77+ | 0.82+ |
| BERT (actuel) | **0.8134** | 0.79 | 0.84 | 0.89 |
| **Objectif MLOps** | **‚â• 0.75** | ‚â• 0.70 | ‚â• 0.70 | ‚â• 0.80 |

## üõ†Ô∏è D√©pannage

### Pipeline ne d√©marre pas

```bash
# V√©rifier que l'API est activ√©e
gcloud services list --enabled | grep aiplatform

# V√©rifier les permissions
gcloud projects get-iam-policy digitalsocialscoreapi
```

### Erreur "Bucket not found"

```bash
# Cr√©er le bucket s'il n'existe pas
gsutil mb -l europe-west1 gs://digitalsocialscoreapi_cloudbuild

# V√©rifier les permissions
gsutil iam get gs://digitalsocialscoreapi_cloudbuild
```

### Composant √©choue

```bash
# Voir les logs d√©taill√©s dans la console Vertex AI
# Ou via gcloud :
gcloud ai custom-jobs list --region=europe-west1
gcloud ai custom-jobs describe JOB_ID --region=europe-west1
```

## üîÑ CI/CD Complet

Une fois int√©gr√© √† Cloud Build, le workflow complet devient :

```
1. git push ‚Üí code_godson
2. Cloud Build triggered
3. Tests unitaires (8/8 pass√©s)
4. Build Docker image
5. Push to GCR
6. Deploy to GKE
7. Smoke tests
8. ‚ú® D√©clenche pipeline Vertex AI
9. Entra√Ænement automatique
10. √âvaluation automatique
11. D√©ploiement conditionnel du nouveau mod√®le
```

## üìö Ressources

- [Vertex AI Pipelines Documentation](https://cloud.google.com/vertex-ai/docs/pipelines)
- [Kubeflow Pipelines SDK](https://www.kubeflow.org/docs/components/pipelines/)
- [ML Pipeline Best Practices](https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning)

## üéâ Prochaines √âtapes

- [ ] Ex√©cution manuelle du pipeline de test
- [ ] Int√©gration avec Cloud Build
- [ ] Monitoring des m√©triques dans Cloud Monitoring
- [ ] Ajout de Cloud Scheduler pour retraining p√©riodique
- [ ] Impl√©mentation de A/B testing entre mod√®les
- [ ] Ajout de drift detection sur les donn√©es

---

**Auteur :** Digital Social Score Team  
**Date :** 2024  
**Version :** 1.0
