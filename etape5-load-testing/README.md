# Ã‰tape 5 : Tests de Charge - Digital Social Score API

## ðŸ“‹ Objectif

Tester la montÃ©e en charge de l'API Digital Social Score hÃ©bergÃ©e sur **http://34.145.51.226** selon les critÃ¨res de la grille d'Ã©valuation.

## ðŸŽ¯ ScÃ©narios de Test

| ScÃ©nario | Utilisateurs | DurÃ©e | Objectif |
|----------|--------------|-------|----------|
| **MontÃ©e progressive** | 0 â†’ 500 | 10 min | Comportement en croissance normale |
| **MontÃ©e rapide** | 0 â†’ 1000 | 2 min | RÃ©action Ã  un pic brutal |
| **Pic soudain** | 0 â†’ 800 | 30 sec | Simulation Black Friday |
| **Maintien 300 RPS** | 300 | 30 min | StabilitÃ© sous charge constante |

## ðŸš€ Installation

### 1. Installer les dÃ©pendances

```powershell
cd etape5-load-testing
pip install -r requirements.txt
```

### 2. VÃ©rifier que Locust est installÃ©

```powershell
locust --version
```

Vous devriez voir : `locust 2.20.0` (ou version similaire)

## âš¡ Utilisation

### Test Rapide (5 minutes)

Pour vÃ©rifier que tout fonctionne :

```powershell
.\quick_test.ps1
```

Cela va :
- âœ… VÃ©rifier la connectivitÃ© avec l'API
- âœ… Envoyer une requÃªte de test
- âœ… Lancer un mini test de charge (10 users, 30s)

### Tests Complets (~1h15)

Pour lancer tous les scÃ©narios de la grille d'Ã©valuation :

```powershell
.\run_tests.ps1
```

**âš ï¸ Attention** : Les tests vont durer environ **1h15** au total :
- MontÃ©e progressive : 10 min
- MontÃ©e rapide : 2 min
- Pic soudain : 30 sec
- Maintien 300 RPS : 30 min

### Lancer Locust en mode interactif (optionnel)

Si vous voulez contrÃ´ler manuellement les tests avec l'interface web :

```powershell
locust --host=http://34.145.51.226
```

Puis ouvrez http://localhost:8089 dans votre navigateur.

## ðŸ“Š RÃ©sultats

Les rÃ©sultats sont gÃ©nÃ©rÃ©s dans un dossier `results_YYYYMMDD_HHMMSS/` avec :

- **Fichiers HTML** : Graphiques interactifs Locust
- **Fichiers CSV** : DonnÃ©es brutes pour analyse
- **RESUME.txt** : RÃ©capitulatif des tests effectuÃ©s

### MÃ©triques collectÃ©es

Pour chaque scÃ©nario, vous aurez :

| MÃ©trique | Description |
|----------|-------------|
| **Requests/s** | DÃ©bit (RPS) - nombre de requÃªtes par seconde |
| **Response Time (ms)** | Latence moyenne |
| **50th percentile** | 50% des requÃªtes sont plus rapides que X ms |
| **95th percentile** | 95% des requÃªtes sont plus rapides que X ms |
| **99th percentile** | 99% des requÃªtes sont plus rapides que X ms |
| **Failure Rate** | Taux d'erreur (%) |
| **Users** | Nombre d'utilisateurs simultanÃ©s |

## ðŸ“ Comment Remplir la Grille d'Ã‰valuation

1. **Ouvrez le fichier HTML** de chaque scÃ©nario
2. **Notez les mÃ©triques** dans le tableau :
   - DÃ©bit max (RPS) â†’ Regardez "Total Requests per Second"
   - Latence moyenne (ms) â†’ Regardez "Average Response Time"
   - Taux d'erreur (%) â†’ Regardez "Failures"
3. **Ajoutez vos observations** (ex: "L'API devient lente aprÃ¨s 500 users")

### Exemple de tableau rempli

| ScÃ©nario | DÃ©bit max (RPS) | Latence moyenne (ms) | Taux d'erreur (%) | Observations |
|----------|-----------------|----------------------|-------------------|--------------|
| MontÃ©e progressive | 45 | 350 | 2.5 | DÃ©gradation aprÃ¨s 300 users |
| MontÃ©e rapide | 80 | 850 | 15.0 | Beaucoup d'erreurs 502 |
| Pic soudain | 60 | 1200 | 25.0 | SystÃ¨me saturÃ© |
| Maintien 300 RPS | 42 | 380 | 3.0 | Stable mais lent |

## ðŸ’¡ Recommandations d'AmÃ©liorations

Selon vos rÃ©sultats, vous devrez proposer des amÃ©liorations :

### Si latence > 500ms
- âœ… **Cache Redis** : Mettre en cache les rÃ©sultats pour les profils identiques
- âœ… **Optimiser le modÃ¨le IA** : RÃ©duire la complexitÃ© des prÃ©dictions

### Si taux d'erreur > 5%
- âœ… **Load Balancer** : Distribuer la charge sur plusieurs instances
- âœ… **Auto-scaling Kubernetes** : Ajouter des pods automatiquement

### Si dÃ©bit < 50 RPS
- âœ… **Horizontal Scaling** : Augmenter le nombre de rÃ©plicas
- âœ… **Optimiser FastAPI** : Utiliser uvicorn avec plusieurs workers

### Pour tous les cas
- âœ… **Monitoring** : Ajouter Prometheus + Grafana
- âœ… **Circuit Breaker** : Ã‰viter la surcharge en rejetant les requÃªtes
- âœ… **Rate Limiting** : Limiter le nombre de requÃªtes par client

## ðŸ“‚ Structure des Fichiers

```
etape5-load-testing/
â”œâ”€â”€ locustfile.py          # Configuration des tests Locust
â”œâ”€â”€ run_tests.ps1          # Script pour lancer tous les scÃ©narios
â”œâ”€â”€ quick_test.ps1         # Test rapide de validation
â”œâ”€â”€ requirements.txt       # DÃ©pendances Python
â”œâ”€â”€ README.md             # Ce fichier
â””â”€â”€ results_*/            # Dossiers de rÃ©sultats (gÃ©nÃ©rÃ©s)
    â”œâ”€â”€ montee_progressive_stats.html
    â”œâ”€â”€ montee_rapide_stats.html
    â”œâ”€â”€ pic_soudain_stats.html
    â”œâ”€â”€ maintien_300rps_stats.html
    â””â”€â”€ RESUME.txt
```

## ðŸ› DÃ©pannage

### Erreur : "locust: command not found"
```powershell
pip install --upgrade locust
```

### Erreur : "Connection refused"
L'API n'est pas accessible. VÃ©rifiez que http://34.145.51.226 fonctionne dans votre navigateur.

### Tests trop longs ?
Modifiez les durÃ©es dans `run_tests.ps1` :
- Changez `10m` â†’ `5m`
- Changez `30m` â†’ `10m`

## ðŸ“š Ressources

- [Documentation Locust](https://docs.locust.io/)
- [Grille d'Ã©valuation](../Grille_Evaluation_Tests_Charge.pdf)
- [API Swagger](http://34.145.51.226/docs)

---

**Bon courage pour vos tests ! ðŸš€**
