"""
API FastAPI pour Digital Social Score - D√©tection de Toxicit√©
Conforme RGPD - Aucune donn√©e stock√©e
"""
import time
import logging
import psutil
from datetime import datetime
from fastapi import FastAPI, HTTPException, Request, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from contextlib import asynccontextmanager
import uvicorn

from .config import (
    API_TITLE, API_DESCRIPTION, API_VERSION, 
    ALLOWED_ORIGINS, LOG_LEVEL, LOG_FORMAT
)
from .models import (
    AnalyzeRequest, AnalyzeResponse, ToxicityCategories,
    HealthResponse, ErrorResponse, StatsResponse
)
from .inference import predictor

# ‚úÖ Import des m√©triques Prometheus (pour monitoring avanc√©)
try:
    from .metrics import setup_metrics, toxicity_requests, toxicity_score, toxicity_processing_time
    METRICS_ENABLED = True
except ImportError:
    METRICS_ENABLED = False
    # Le logger sera d√©fini plus bas

# ‚úÖ CORRECTION: Configuration du logging s√©curis√©e
try:
    # Convertir le niveau de log en niveau logging appropri√©
    if isinstance(LOG_LEVEL, str):
        log_level = getattr(logging, LOG_LEVEL.upper(), logging.INFO)
    else:
        log_level = LOG_LEVEL
    
    logging.basicConfig(level=log_level, format=LOG_FORMAT)
except (AttributeError, ValueError):
    # Fallback en cas d'erreur
    logging.basicConfig(level=logging.INFO, format=LOG_FORMAT)

logger = logging.getLogger(__name__)

# Variables globales pour les statistiques
app_start_time = time.time()
request_stats = {
    "total_requests": 0,
    "requests_per_model": {"bert": 0, "simple": 0},
    "processing_times": [],
    "toxicity_distribution": {"low": 0, "medium": 0, "high": 0, "extreme": 0},
    "last_request": None
}

@asynccontextmanager
async def lifespan(app: FastAPI):
    """Gestion du cycle de vie de l'application"""
    # Startup
    logger.info("üöÄ D√©marrage de l'API Digital Social Score")
    logger.info("üì¶ Pr√©-chargement des mod√®les...")
    
    # Pr√©-charger le mod√®le BERT (le plus utilis√©)
    try:
        predictor.load_bert_model()
        logger.info("‚úÖ Mod√®le BERT pr√©-charg√©")
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è √âchec du pr√©-chargement BERT: {e}")
    
    # Pr√©-charger le mod√®le simple
    try:
        predictor.load_simple_model()
        logger.info("‚úÖ Mod√®le simple pr√©-charg√©")
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è √âchec du pr√©-chargement mod√®le simple: {e}")
    
    logger.info("üéâ API pr√™te √† traiter les requ√™tes")
    
    yield
    
    # Shutdown
    logger.info("üõë Arr√™t de l'API Digital Social Score")

# Cr√©ation de l'application FastAPI
app = FastAPI(
    title=API_TITLE,
    description=API_DESCRIPTION,
    version=API_VERSION,
    lifespan=lifespan,
    docs_url="/docs",
    redoc_url="/redoc"
)

# ‚úÖ ACTIVATION PROMETHEUS - M√©triques disponibles sur /metrics
if METRICS_ENABLED:
    setup_metrics(app)
    logger.info("üìä M√©triques Prometheus activ√©es sur /metrics")
else:
    logger.warning("‚ö†Ô∏è M√©triques Prometheus d√©sactiv√©es (module non trouv√©)")

# Configuration CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=ALLOWED_ORIGINS,
    allow_credentials=True,
    allow_methods=["GET", "POST"],
    allow_headers=["*"],
)

# Middleware pour logging des requ√™tes
@app.middleware("http")
async def log_requests(request: Request, call_next):
    """Log toutes les requ√™tes avec timing"""
    start_time = time.time()
    
    # Traiter la requ√™te
    response = await call_next(request)
    
    # Calculer le temps de traitement
    process_time = time.time() - start_time
    
    # Logger la requ√™te
    logger.info(
        f"{request.method} {request.url.path} - "
        f"Status: {response.status_code} - "
        f"Time: {process_time:.3f}s"
    )
    
    return response

def update_stats(model_used: str, processing_time: float, toxicity_level: str):
    """Met √† jour les statistiques globales"""
    request_stats["total_requests"] += 1
    request_stats["requests_per_model"][model_used] += 1
    request_stats["processing_times"].append(processing_time)
    request_stats["toxicity_distribution"][toxicity_level] += 1
    request_stats["last_request"] = datetime.now()
    
    # Garder seulement les 1000 derniers temps de traitement
    if len(request_stats["processing_times"]) > 1000:
        request_stats["processing_times"] = request_stats["processing_times"][-1000:]

@app.get("/", tags=["General"])
async def root():
    """Point d'entr√©e principal de l'API"""
    return {
        "message": "üõ°Ô∏è Digital Social Score API - D√©tection de Toxicit√©",
        "version": API_VERSION,
        "status": "operational",
        "docs": "/docs",
        "health": "/health",
        "analyze_endpoint": "/analyze"
    }

@app.get("/health", response_model=HealthResponse, tags=["Monitoring"])
async def health_check():
    """Endpoint de v√©rification de sant√© de l'API"""
    try:
        uptime = time.time() - app_start_time
        memory_usage = psutil.Process().memory_info().rss / 1024 / 1024  # MB
        
        # V√©rifier si au moins un mod√®le est charg√©
        model_loaded = any([
            predictor.is_model_loaded("bert"),
            predictor.is_model_loaded("simple")
        ])
        
        return HealthResponse(
            status="healthy" if model_loaded else "degraded",
            version=API_VERSION,
            model_loaded=model_loaded,
            uptime_seconds=uptime,
            memory_usage_mb=memory_usage
        )
    except Exception as e:
        logger.error(f"Erreur health check: {e}")
        raise HTTPException(status_code=500, detail="Health check failed")

@app.get("/models/info", tags=["Models"])
async def models_info():
    """Informations sur les mod√®les charg√©s"""
    try:
        return predictor.get_model_info()
    except Exception as e:
        logger.error(f"Erreur lors de la r√©cup√©ration des infos mod√®les: {e}")
        raise HTTPException(status_code=500, detail="Erreur interne")

@app.get("/stats", response_model=StatsResponse, tags=["Monitoring"])
async def get_stats():
    """Statistiques d'utilisation de l'API"""
    try:
        avg_processing_time = (
            sum(request_stats["processing_times"]) / len(request_stats["processing_times"])
            if request_stats["processing_times"] else 0.0
        )
        
        return StatsResponse(
            total_requests=request_stats["total_requests"],
            requests_per_model=request_stats["requests_per_model"],
            average_processing_time_ms=avg_processing_time,
            toxicity_distribution=request_stats["toxicity_distribution"],
            last_request=request_stats["last_request"]
        )
    except Exception as e:
        logger.error(f"Erreur lors de la r√©cup√©ration des stats: {e}")
        raise HTTPException(status_code=500, detail="Erreur interne")

@app.post("/analyze", response_model=AnalyzeResponse, tags=["AI Analysis"])
async def analyze_toxicity(
    request: AnalyzeRequest,
    background_tasks: BackgroundTasks
):
    """
    üéØ **Analyse de Toxicit√©**
    
    Analyse un texte et retourne un score de toxicit√© de 0 √† 100.
    
    - **text**: Le texte √† analyser (max 5000 caract√®res)    - **model**: Mod√®le √† utiliser ("bert" ou "simple")
    
    **Note RGPD**: Aucune donn√©e n'est stock√©e ou logged.
    """
    try:
        logger.info(f"Analyse demand√©e avec mod√®le: {request.model}")
        
        # Timer pour Prometheus
        start_time = time.time()
        
        # Effectuer la pr√©diction
        result = predictor.predict(request.text, request.model)
        
        # ‚úÖ Enregistrer les m√©triques Prometheus
        if METRICS_ENABLED:
            # Compter la requ√™te
            toxicity_requests.labels(
                model_type=result["model_used"],
                status="success"
            ).inc()
            
            # Enregistrer le score
            toxicity_score.observe(result["score"])
            
            # Enregistrer le temps de traitement
            toxicity_processing_time.labels(
                model_type=result["model_used"]
            ).observe(result["processing_time_ms"] / 1000)  # Convertir ms en secondes
        
        # Cr√©er la r√©ponse
        response = AnalyzeResponse(
            score=result["score"],
            toxicity_level=result["toxicity_level"],
            confidence=result["confidence"],
            categories=ToxicityCategories(**result["categories"]),
            model_used=result["model_used"],
            processing_time_ms=result["processing_time_ms"]
        )
        
        # Mettre √† jour les statistiques en arri√®re-plan
        background_tasks.add_task(
            update_stats,
            result["model_used"],
            result["processing_time_ms"],
            result["toxicity_level"]
        )
        
        logger.info(f"Analyse termin√©e - Score: {result['score']} - Temps: {result['processing_time_ms']:.1f}ms")
        
        return response
        
    except ValueError as e:
        # ‚úÖ Enregistrer l'erreur dans Prometheus
        if METRICS_ENABLED:
            toxicity_requests.labels(model_type=request.model, status="validation_error").inc()
        logger.warning(f"Erreur de validation: {e}")
        raise HTTPException(status_code=422, detail=str(e))
    except RuntimeError as e:
        # ‚úÖ Enregistrer l'erreur dans Prometheus
        if METRICS_ENABLED:
            toxicity_requests.labels(model_type=request.model, status="model_error").inc()
        logger.error(f"Erreur mod√®le: {e}")
        raise HTTPException(status_code=503, detail="Mod√®le temporairement indisponible")
    except Exception as e:
        # ‚úÖ Enregistrer l'erreur dans Prometheus
        if METRICS_ENABLED:
            toxicity_requests.labels(model_type=request.model, status="server_error").inc()
        logger.error(f"Erreur inattendue lors de l'analyse: {e}")
        raise HTTPException(status_code=500, detail="Erreur interne du serveur")

@app.exception_handler(Exception)
async def global_exception_handler(request: Request, exc: Exception):
    """Gestionnaire global d'exceptions"""
    logger.error(f"Exception non g√©r√©e: {exc}")
    
    return JSONResponse(
        status_code=500,
        content=ErrorResponse(
            error="Internal Server Error",
            message="Une erreur inattendue s'est produite"
        ).model_dump(mode='json')
    )

@app.exception_handler(HTTPException)
async def http_exception_handler(request: Request, exc: HTTPException):
    """Gestionnaire d'exceptions HTTP"""
    return JSONResponse(
        status_code=exc.status_code,
        content=ErrorResponse(
            error=f"HTTP {exc.status_code}",
            message=exc.detail
        ).model_dump(mode='json')
    )

if __name__ == "__main__":
    # ‚úÖ CORRECTION: Gestion s√©curis√©e du log level pour uvicorn
    try:
        uvicorn_log_level = LOG_LEVEL.lower() if isinstance(LOG_LEVEL, str) else "info"
    except:
        uvicorn_log_level = "info"
        
    uvicorn.run(
        "app.main:app",
        host="0.0.0.0",
        port=8080,
        reload=True,
        log_level=uvicorn_log_level
    )