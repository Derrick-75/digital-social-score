# Ã‰tape 3 : DÃ©ploiement du ModÃ¨le en API Cloud

## ğŸ¯ Objectifs PÃ©dagogiques

- Transformer le modÃ¨le IA en service accessible
- Utiliser FastAPI, Flask ou un service Cloud (Vertex AI, Scaleway, AWS)

## ğŸ“‹ Exercices

### 1. Export du ModÃ¨le
- [ ] Sauvegarder le modÃ¨le entraÃ®nÃ©
- [ ] CrÃ©er script de chargement optimisÃ©
- [ ] Tester le chargement et l'infÃ©rence

### 2. CrÃ©ation de l'API
- [ ] Choisir framework : **FastAPI (recommandÃ©)** ou Flask
- [ ] CrÃ©er endpoint POST `/analyze`
- [ ] DÃ©finir schÃ©ma de requÃªte/rÃ©ponse
- [ ] ImplÃ©menter la logique de scoring

### 3. DÃ©ploiement Cloud
- [ ] Containeriser avec Docker
- [ ] DÃ©ployer sur plateforme Cloud :
  - AWS (Lambda + API Gateway)
  - GCP (Cloud Run)
  - Scaleway
- [ ] Configurer domaine et HTTPS

### 4. Tests de l'API
- [ ] Tester avec curl/Postman
- [ ] CrÃ©er suite de tests (pytest)
- [ ] Documenter exemples de requÃªtes

## ğŸ› ï¸ Technologies

```bash
pip install fastapi uvicorn pydantic transformers torch
```

## ğŸ“ Structure

```
etape3-api/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                    # Point d'entrÃ©e FastAPI
â”‚   â”œâ”€â”€ models.py                  # SchÃ©mas Pydantic
â”‚   â”œâ”€â”€ inference.py               # Logique d'infÃ©rence
â”‚   â””â”€â”€ config.py                  # Configuration
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_api.py                # Tests unitaires
â”‚   â””â”€â”€ test_inference.py
â”œâ”€â”€ Dockerfile                     # Image Docker
â”œâ”€â”€ requirements.txt               # DÃ©pendances Python
â””â”€â”€ README.md
```

## ğŸš€ Architecture API

```
Client
  â†“ POST /analyze
API Gateway
  â†“
FastAPI App
  â†“
Model Inference
  â†“
Response (score + dÃ©tails)
```

## ğŸ“ Exemple de RequÃªte/RÃ©ponse

### RequÃªte POST `/analyze`
```json
{
  "text": "Ce commentaire est vraiment mÃ©chant et insultant"
}
```

### RÃ©ponse
```json
{
  "score": 87,
  "toxicity_level": "high",
  "categories": {
    "insult": 0.85,
    "threat": 0.12,
    "hate": 0.45
  },
  "processing_time_ms": 245
}
```

## ğŸ³ Dockerfile Exemple

```dockerfile
FROM python:3.9-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY app/ ./app/
COPY models/ ./models/

CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8080"]
```

## ğŸ“Š Livrables

- [ ] Code API complet et fonctionnel
- [ ] Documentation OpenAPI automatique (FastAPI)
- [ ] Dockerfile et image buildÃ©e
- [ ] API dÃ©ployÃ©e et accessible (URL publique)
- [ ] Collection Postman avec exemples
- [ ] Tests unitaires (couverture > 80%)

## âœ… CritÃ¨res de Validation

- âœ… API rÃ©pond correctement aux requÃªtes
- âœ… Temps de rÃ©ponse < 500ms
- âœ… Validation des entrÃ©es (Pydantic)
- âœ… Gestion des erreurs (404, 422, 500)
- âœ… Documentation interactive accessible
- âœ… DÃ©ployÃ©e sur Cloud avec HTTPS

## ğŸ’¡ Bonnes Pratiques

### FastAPI Features Ã  Utiliser
- **Validation automatique** avec Pydantic
- **Documentation auto** : `/docs` (Swagger UI)
- **Performance** : async/await
- **Type hints** : meilleure maintenabilitÃ©

### Optimisations
- **Cache du modÃ¨le** : charger une seule fois au startup
- **Batch processing** : traiter plusieurs textes ensemble
- **Rate limiting** : limiter les abus

### Monitoring
- Logs structurÃ©s (JSON)
- Temps de rÃ©ponse par endpoint
- Erreurs HTTP

## ğŸŒ Options de DÃ©ploiement

| Plateforme | Avantages | InconvÃ©nients |
|------------|-----------|---------------|
| **AWS Lambda** | Serverless, pay-per-use | Cold start, limite 15min |
| **GCP Cloud Run** | Simple, auto-scale | CoÃ»t si trafic Ã©levÃ© |
| **Scaleway** | EuropÃ©en, RGPD-friendly | Moins de features |
| **Heroku** | Gratuit (hobby), simple | LimitÃ© en perfs |

## ğŸ“š Ressources

- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [Docker Best Practices](https://docs.docker.com/develop/dev-best-practices/)
- [AWS Lambda + FastAPI](https://mangum.io/)
