# Ã‰tape 2 : PrÃ©paration et EntraÃ®nement d'un ModÃ¨le IA

## ğŸ¯ Objectifs PÃ©dagogiques

- ApprÃ©hender le nettoyage de texte et les modÃ¨les d'IA
- EntraÃ®ner et comparer un modÃ¨le simple et un modÃ¨le avancÃ© (BERT)

## ğŸ“‹ Exercices

### 1. Nettoyage des Textes
- [ ] Gestion de la ponctuation
- [ ] Traitement des emojis
- [ ] Normalisation de la casse
- [ ] Suppression des caractÃ¨res spÃ©ciaux
- [ ] Tokenization

### 2. EntraÃ®nement ModÃ¨le Statistique
- [ ] Vectorisation TF-IDF ou Bag of Words
- [ ] ModÃ¨le de classification simple :
  - Logistic Regression
  - Naive Bayes
  - Random Forest
- [ ] EntraÃ®nement et validation

### 3. EntraÃ®nement ModÃ¨le AvancÃ©
- [ ] Choix : LSTM ou BERT (recommandÃ©)
- [ ] Utiliser HuggingFace Transformers
- [ ] Fine-tuning sur dataset toxicitÃ©
- [ ] Optimisation hyperparamÃ¨tres

### 4. Comparaison des ModÃ¨les
- [ ] MÃ©triques :
  - PrÃ©cision (Precision)
  - Rappel (Recall)
  - F1-Score
  - AUC-ROC
  - Temps d'infÃ©rence
- [ ] Matrice de confusion
- [ ] Analyse des erreurs

## ğŸ› ï¸ Technologies

```bash
pip install transformers torch scikit-learn pandas numpy nltk
```

## ğŸ“ Structure

```
etape2-modele-ia/
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ preprocessing.ipynb        # Nettoyage et prÃ©paration
â”‚   â”œâ”€â”€ model_simple.ipynb         # ModÃ¨le statistique
â”‚   â””â”€â”€ model_bert.ipynb           # ModÃ¨le BERT
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ train_simple.py            # EntraÃ®nement modÃ¨le simple
â”‚   â”œâ”€â”€ train_bert.py              # EntraÃ®nement BERT
â”‚   â””â”€â”€ utils.py                   # Fonctions utilitaires
â”œâ”€â”€ evaluation/
â”‚   â”œâ”€â”€ compare_models.py          # Comparaison performances
â”‚   â””â”€â”€ metrics.py                 # Calcul mÃ©triques
â””â”€â”€ models/
    â”œâ”€â”€ simple_model.pkl           # ModÃ¨le simple sauvegardÃ©
    â””â”€â”€ bert_model/                # ModÃ¨le BERT sauvegardÃ©
```

## ğŸ§ª Pipeline de Traitement

```
Texte brut
    â†“
Nettoyage (ponctuation, emojis, casse)
    â†“
Tokenization
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ModÃ¨le Statistique  â”‚    ModÃ¨le BERT       â”‚
â”‚  (TF-IDF + LR)       â”‚  (Transformers)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“                           â†“
  Score 0-100              Score 0-100
```

## ğŸ“Š Livrables

- [ ] Scripts d'entraÃ®nement fonctionnels
- [ ] ModÃ¨les sauvegardÃ©s et exportÃ©s
- [ ] Rapport de comparaison dÃ©taillÃ© :
  - Tableau comparatif des mÃ©triques
  - Graphiques de performance
  - Analyse temps de traitement
- [ ] Recommandation du meilleur modÃ¨le pour production

## âœ… CritÃ¨res de Validation

- âœ… F1-Score > 0.75 pour le meilleur modÃ¨le
- âœ… Temps d'infÃ©rence < 500ms par texte
- âœ… Comparaison objective et documentÃ©e
- âœ… ModÃ¨le exportÃ© et rÃ©utilisable

## ğŸ’¡ Recommandations

### ModÃ¨le Simple (Baseline)
- **Avantages** : Rapide, lÃ©ger, facile Ã  dÃ©ployer
- **InconvÃ©nients** : Moins prÃ©cis, ne comprend pas le contexte

### ModÃ¨le BERT
- **Avantages** : Ã‰tat de l'art, comprend le contexte
- **InconvÃ©nients** : Lourd, nÃ©cessite GPU, plus lent

### Choix pour Production
Recommandation : Commencer avec BERT pour la prÃ©cision, puis optimiser avec :
- Distillation de modÃ¨le (DistilBERT)
- Quantization
- ONNX Runtime

## ğŸ“š Ressources

- [HuggingFace Transformers](https://huggingface.co/docs/transformers/index)
- [BERT Paper](https://arxiv.org/abs/1810.04805)
- [Scikit-learn Guide](https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html)
