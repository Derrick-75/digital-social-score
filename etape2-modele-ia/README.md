# Ã‰tape 2 : PrÃ©paration et EntraÃ®nement d'un ModÃ¨le IA

## ğŸ¯ Objectifs PÃ©dagogiques

- ApprÃ©hender le nettoyage de texte et les modÃ¨les d'IA
- EntraÃ®ner et comparer un modÃ¨le simple et un modÃ¨le avancÃ© (BERT)

## ğŸ“‹ Exercices

### 1. Nettoyage des Textes âœ… TERMINÃ‰
- [x] Gestion de la ponctuation
- [x] Traitement des emojis
- [x] Normalisation de la casse
- [x] Suppression des caractÃ¨res spÃ©ciaux
- [x] Tokenization

### 2. EntraÃ®nement ModÃ¨le Statistique âœ… TERMINÃ‰
- [x] Vectorisation TF-IDF ou Bag of Words
- [x] ModÃ¨le de classification simple :
  - Logistic Regression
  - Naive Bayes
  - Random Forest
- [x] EntraÃ®nement et validation

### 3. EntraÃ®nement ModÃ¨le AvancÃ© âœ… TERMINÃ‰
- [x] Choix : LSTM ou BERT (recommandÃ©)
- [x] Utiliser HuggingFace Transformers
- [x] Fine-tuning sur dataset toxicitÃ©
- [x] Optimisation hyperparamÃ¨tres

### 4. Comparaison des ModÃ¨les âœ… TERMINÃ‰
- [x] MÃ©triques :
  - PrÃ©cision (Precision)
  - Rappel (Recall)
  - F1-Score
  - AUC-ROC
  - Temps d'infÃ©rence
- [x] Matrice de confusion
- [x] Analyse des erreurs

## ğŸ› ï¸ Technologies

```bash
pip install transformers torch scikit-learn pandas numpy nltk
```

## ğŸ“ Structure

```
etape2-modele-ia/
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ preprocessing.ipynb        # Nettoyage et prÃ©paration
â”‚   â”œâ”€â”€ model_simple.ipynb         # ModÃ¨le statistique
â”‚   â””â”€â”€ model_bert.ipynb           # ModÃ¨le BERT
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ train_simple.py            # EntraÃ®nement modÃ¨le simple
â”‚   â”œâ”€â”€ train_bert.py              # EntraÃ®nement BERT
â”‚   â””â”€â”€ utils.py                   # Fonctions utilitaires
â”œâ”€â”€ evaluation/
â”‚   â”œâ”€â”€ compare_models.py          # Comparaison performances
â”‚   â””â”€â”€ metrics.py                 # Calcul mÃ©triques
â””â”€â”€ models/
    â”œâ”€â”€ simple_model.pkl           # ModÃ¨le simple sauvegardÃ©
    â””â”€â”€ bert_model/                # ModÃ¨le BERT sauvegardÃ©
```

## ğŸ§ª Pipeline de Traitement

```
Texte brut
    â†“
Nettoyage (ponctuation, emojis, casse)
    â†“
Tokenization
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ModÃ¨le Statistique  â”‚    ModÃ¨le BERT       â”‚
â”‚  (TF-IDF + LR)       â”‚  (Transformers)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“                           â†“
  Score 0-100              Score 0-100
```

## ğŸ“Š Livrables âœ… TERMINÃ‰S

- [x] Scripts d'entraÃ®nement fonctionnels
- [x] ModÃ¨les sauvegardÃ©s et exportÃ©s
- [x] Rapport de comparaison dÃ©taillÃ© :
  - Tableau comparatif des mÃ©triques
  - Graphiques de performance
  - Analyse temps de traitement
- [x] Recommandation du meilleur modÃ¨le pour production

## âœ… CritÃ¨res de Validation

- âœ… F1-Score > 0.75 pour le meilleur modÃ¨le
- âœ… Temps d'infÃ©rence < 500ms par texte
- âœ… Comparaison objective et documentÃ©e
- âœ… ModÃ¨le exportÃ© et rÃ©utilisable

## ğŸ† RÃ©sultats Finaux

### ModÃ¨le Simple (TF-IDF + Logistic Regression)
- **F1-Score** : 0.7149
- **Accuracy** : 93.6%
- **AUC-ROC** : 0.9508
- **Temps infÃ©rence** : ~0ms par texte
- **Fichiers** : `models/simple_model/best_simple_model.pkl`

### ModÃ¨le BERT (martin-ha/toxic-comment-model)
- **ModÃ¨le** : SpÃ©cialisÃ© pour dÃ©tection de toxicitÃ©
- **Type** : BERT prÃ©-entraÃ®nÃ© optimisÃ©
- **Taille** : 255MB
- **Fichiers** : `models/bert_model/` (tÃ©lÃ©chargÃ© automatiquement)
- **Status** : âœ… OpÃ©rationnel dans l'API

## ğŸ’¡ Recommandations

### ModÃ¨le Simple (Baseline)
- **Avantages** : Rapide, lÃ©ger, facile Ã  dÃ©ployer
- **InconvÃ©nients** : Moins prÃ©cis, ne comprend pas le contexte

### ModÃ¨le BERT
- **Avantages** : Ã‰tat de l'art, comprend le contexte
- **InconvÃ©nients** : Lourd, nÃ©cessite GPU, plus lent

### Choix pour Production
Recommandation : Commencer avec BERT pour la prÃ©cision, puis optimiser avec :
- Distillation de modÃ¨le (DistilBERT)
- Quantization
- ONNX Runtime

## ğŸ“š Ressources

- [HuggingFace Transformers](https://huggingface.co/docs/transformers/index)
- [BERT Paper](https://arxiv.org/abs/1810.04805)
- [Scikit-learn Guide](https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html)
