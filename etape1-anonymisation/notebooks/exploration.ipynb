{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46062978",
   "metadata": {},
   "source": [
    "# Ã‰tape 1 : Exploration et Analyse des DonnÃ©es\n",
    "\n",
    "## Objectifs\n",
    "- Explorer les donnÃ©es enrichies\n",
    "- Identifier les donnÃ©es personnelles prÃ©sentes\n",
    "- PrÃ©parer l'anonymisation avec spaCy NER\n",
    "- Analyser les risques RGPD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73542041",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import re\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configuration\n",
    "plt.style.use('default')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f249530c",
   "metadata": {},
   "source": [
    "## 1. Chargement des DonnÃ©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c125f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les donnÃ©es enrichies\n",
    "train_df = pd.read_csv('../data/raw/train_advanced.csv')\n",
    "test_df = pd.read_csv('../data/raw/test_advanced.csv')\n",
    "\n",
    "print(f\"ğŸ“Š DonnÃ©es d'entraÃ®nement: {train_df.shape}\")\n",
    "print(f\"ğŸ“Š DonnÃ©es de test: {test_df.shape}\")\n",
    "\n",
    "# Afficher les premiÃ¨res lignes\n",
    "print(\"\\nğŸ” AperÃ§u des donnÃ©es d'entraÃ®nement:\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed78a207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informations sur les colonnes\n",
    "print(\"ğŸ“‹ Colonnes disponibles:\")\n",
    "for i, col in enumerate(train_df.columns):\n",
    "    print(f\"{i+1:2d}. {col}\")\n",
    "\n",
    "print(\"\\nğŸ“ˆ Types de donnÃ©es:\")\n",
    "print(train_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db632d8",
   "metadata": {},
   "source": [
    "## 2. Analyse des DonnÃ©es Personnelles AjoutÃ©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f074c960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyser les donnÃ©es personnelles ajoutÃ©es par le script d'enrichissement\n",
    "personal_data_columns = ['username', 'email', 'ip_address', 'phone_number', 'country']\n",
    "\n",
    "print(\"ğŸ”’ DONNÃ‰ES PERSONNELLES AJOUTÃ‰ES:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for col in personal_data_columns:\n",
    "    if col in train_df.columns:\n",
    "        print(f\"\\nğŸ“§ {col.upper()}:\")\n",
    "        print(f\"   Exemples: {train_df[col].head(3).tolist()}\")\n",
    "        print(f\"   Valeurs uniques: {train_df[col].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282e51e2",
   "metadata": {},
   "source": [
    "## 3. Analyse des Commentaires avec spaCy NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4cb938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le modÃ¨le spaCy\n",
    "print(\"ğŸš€ Chargement du modÃ¨le spaCy...\")\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "print(\"âœ… ModÃ¨le chargÃ© avec succÃ¨s!\")\n",
    "\n",
    "# Test rapide\n",
    "test_text = \"Hello John Doe, please contact me at john.doe@email.com or call +1-555-123-4567\"\n",
    "doc = nlp(test_text)\n",
    "\n",
    "print(\"\\nğŸ§ª Test de reconnaissance d'entitÃ©s:\")\n",
    "print(f\"Texte: {test_text}\")\n",
    "print(\"EntitÃ©s dÃ©tectÃ©es:\")\n",
    "for ent in doc.ents:\n",
    "    print(f\"  - {ent.text} ({ent.label_}) : {spacy.explain(ent.label_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dce5806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyser un Ã©chantillon de commentaires pour dÃ©tecter des entitÃ©s\n",
    "def analyze_entities_in_comments(df, sample_size=100):\n",
    "    \"\"\"Analyse les entitÃ©s nommÃ©es dans un Ã©chantillon de commentaires\"\"\"\n",
    "    \n",
    "    sample_comments = df['comment_text'].dropna().sample(min(sample_size, len(df))).tolist()\n",
    "    \n",
    "    all_entities = []\n",
    "    entity_counts = Counter()\n",
    "    \n",
    "    print(f\"ğŸ” Analyse de {len(sample_comments)} commentaires...\")\n",
    "    \n",
    "    for i, comment in enumerate(sample_comments):\n",
    "        if i % 20 == 0:\n",
    "            print(f\"  Progression: {i}/{len(sample_comments)}\")\n",
    "            \n",
    "        # Limiter la longueur pour Ã©viter les timeouts\n",
    "        if len(comment) > 1000:\n",
    "            comment = comment[:1000]\n",
    "            \n",
    "        try:\n",
    "            doc = nlp(comment)\n",
    "            for ent in doc.ents:\n",
    "                all_entities.append({\n",
    "                    'text': ent.text,\n",
    "                    'label': ent.label_,\n",
    "                    'description': spacy.explain(ent.label_),\n",
    "                    'comment_id': i\n",
    "                })\n",
    "                entity_counts[ent.label_] += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur avec commentaire {i}: {str(e)[:50]}\")\n",
    "            continue\n",
    "    \n",
    "    return all_entities, entity_counts\n",
    "\n",
    "# Lancer l'analyse\n",
    "entities, entity_counts = analyze_entities_in_comments(train_df, sample_size=50)\n",
    "\n",
    "print(\"\\nğŸ“Š RÃ‰SULTATS DE L'ANALYSE NER:\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Total d'entitÃ©s trouvÃ©es: {len(entities)}\")\n",
    "print(\"\\nTypes d'entitÃ©s les plus frÃ©quents:\")\n",
    "for label, count in entity_counts.most_common(10):\n",
    "    print(f\"  {label:10s}: {count:3d} ({spacy.explain(label)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4031aeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher quelques exemples d'entitÃ©s dÃ©tectÃ©es\n",
    "if entities:\n",
    "    entities_df = pd.DataFrame(entities)\n",
    "    \n",
    "    print(\"\\nğŸ” EXEMPLES D'ENTITÃ‰S DÃ‰TECTÃ‰ES:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Grouper par type d'entitÃ©\n",
    "    for label in ['PERSON', 'ORG', 'GPE', 'EMAIL', 'PHONE']:\n",
    "        if label in entities_df['label'].values:\n",
    "            examples = entities_df[entities_df['label'] == label]['text'].unique()[:5]\n",
    "            print(f\"\\n{label} ({spacy.explain(label)}):\")\n",
    "            for example in examples:\n",
    "                print(f\"  - {example}\")\n",
    "else:\n",
    "    print(\"âš ï¸ Aucune entitÃ© dÃ©tectÃ©e dans l'Ã©chantillon\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d0d584",
   "metadata": {},
   "source": [
    "## 4. DÃ©tection de Patterns de DonnÃ©es Personnelles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a6da0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patterns regex pour dÃ©tecter des donnÃ©es personnelles\n",
    "patterns = {\n",
    "    'email': r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b',\n",
    "    'phone': r'\\b(?:\\+?1[-.]?)?(?:\\(?\\d{3}\\)?[-.]?)?\\d{3}[-.]?\\d{4}\\b',\n",
    "    'ip_address': r'\\b(?:[0-9]{1,3}\\.){3}[0-9]{1,3}\\b',\n",
    "    'credit_card': r'\\b(?:\\d{4}[-\\s]?){3}\\d{4}\\b',\n",
    "    'ssn': r'\\b\\d{3}-\\d{2}-\\d{4}\\b'\n",
    "}\n",
    "\n",
    "def find_personal_data_patterns(text_series, max_samples=1000):\n",
    "    \"\"\"Trouve des patterns de donnÃ©es personnelles dans les textes\"\"\"\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Prendre un Ã©chantillon pour l'analyse\n",
    "    sample = text_series.dropna().sample(min(max_samples, len(text_series)))\n",
    "    \n",
    "    print(f\"ğŸ” Recherche de patterns dans {len(sample)} commentaires...\")\n",
    "    \n",
    "    for pattern_name, pattern in patterns.items():\n",
    "        matches = []\n",
    "        for text in sample:\n",
    "            if isinstance(text, str):\n",
    "                found = re.findall(pattern, text, re.IGNORECASE)\n",
    "                matches.extend(found)\n",
    "        \n",
    "        results[pattern_name] = {\n",
    "            'count': len(matches),\n",
    "            'examples': list(set(matches))[:5] if matches else []\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Analyser les commentaires\n",
    "personal_data_found = find_personal_data_patterns(train_df['comment_text'])\n",
    "\n",
    "print(\"\\nğŸš¨ DONNÃ‰ES PERSONNELLES DÃ‰TECTÃ‰ES DANS LES COMMENTAIRES:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for data_type, info in personal_data_found.items():\n",
    "    print(f\"\\n{data_type.upper()}:\")\n",
    "    print(f\"  Occurrences trouvÃ©es: {info['count']}\")\n",
    "    if info['examples']:\n",
    "        print(f\"  Exemples: {info['examples']}\")\n",
    "    else:\n",
    "        print(f\"  Aucun exemple trouvÃ©\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65c9ce1",
   "metadata": {},
   "source": [
    "## 5. Statistiques GÃ©nÃ©rales sur les DonnÃ©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c2e20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistiques de base\n",
    "print(\"ğŸ“Š STATISTIQUES GÃ‰NÃ‰RALES:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "print(f\"\\nğŸ“ˆ Taille des datasets:\")\n",
    "print(f\"  Train: {train_df.shape[0]:,} lignes, {train_df.shape[1]} colonnes\")\n",
    "print(f\"  Test:  {test_df.shape[0]:,} lignes, {test_df.shape[1]} colonnes\")\n",
    "\n",
    "print(f\"\\nğŸ“ Longueur des commentaires (train):\")\n",
    "train_df['comment_length'] = train_df['comment_text'].str.len()\n",
    "print(f\"  Moyenne: {train_df['comment_length'].mean():.1f} caractÃ¨res\")\n",
    "print(f\"  MÃ©diane: {train_df['comment_length'].median():.1f} caractÃ¨res\")\n",
    "print(f\"  Min: {train_df['comment_length'].min()} caractÃ¨res\")\n",
    "print(f\"  Max: {train_df['comment_length'].max()} caractÃ¨res\")\n",
    "\n",
    "# Histogramme des longueurs\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(train_df['comment_length'], bins=50, alpha=0.7, edgecolor='black')\n",
    "plt.title('Distribution de la longueur des commentaires')\n",
    "plt.xlabel('Longueur (caractÃ¨res)')\n",
    "plt.ylabel('FrÃ©quence')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3290711b",
   "metadata": {},
   "source": [
    "## 6. Analyse RGPD - Risques IdentifiÃ©s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddcda7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"âš–ï¸ ANALYSE RGPD - RISQUES IDENTIFIÃ‰S:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "risks = []\n",
    "\n",
    "# VÃ©rifier les colonnes de donnÃ©es personnelles\n",
    "personal_columns = ['username', 'email', 'ip_address', 'phone_number', 'country']\n",
    "found_personal_columns = [col for col in personal_columns if col in train_df.columns]\n",
    "\n",
    "if found_personal_columns:\n",
    "    risks.append(f\"ğŸ”´ Ã‰LEVÃ‰: Colonnes de donnÃ©es personnelles prÃ©sentes: {found_personal_columns}\")\n",
    "\n",
    "# VÃ©rifier les entitÃ©s dans les commentaires\n",
    "risky_entities = ['PERSON', 'ORG', 'GPE']\n",
    "found_risky_entities = [ent for ent in risky_entities if ent in entity_counts]\n",
    "\n",
    "if found_risky_entities:\n",
    "    risks.append(f\"ğŸŸ¡ MOYEN: EntitÃ©s nommÃ©es dans les commentaires: {found_risky_entities}\")\n",
    "\n",
    "# VÃ©rifier les patterns de donnÃ©es personnelles\n",
    "risky_patterns = [pattern for pattern, info in personal_data_found.items() if info['count'] > 0]\n",
    "\n",
    "if risky_patterns:\n",
    "    risks.append(f\"ğŸŸ¡ MOYEN: Patterns de donnÃ©es personnelles: {risky_patterns}\")\n",
    "\n",
    "if not risks:\n",
    "    risks.append(\"ğŸŸ¢ FAIBLE: Aucun risque majeur identifiÃ©\")\n",
    "\n",
    "for risk in risks:\n",
    "    print(f\"  {risk}\")\n",
    "\n",
    "print(\"\\nğŸ“‹ ACTIONS REQUISES:\")\n",
    "print(\"  1. âœ… Anonymiser toutes les colonnes de donnÃ©es personnelles\")\n",
    "print(\"  2. âœ… Appliquer NER sur les commentaires pour masquer les entitÃ©s\")\n",
    "print(\"  3. âœ… Utiliser des patterns regex pour nettoyer les donnÃ©es restantes\")\n",
    "print(\"  4. âœ… Sauvegarder les versions anonymisÃ©es dans data/anonymized/\")\n",
    "print(\"  5. âœ… ComplÃ©ter le registre RGPD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf57193",
   "metadata": {},
   "source": [
    "## 7. Conclusion et Prochaines Ã‰tapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05b9abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"âœ… EXPLORATION TERMINÃ‰E - RÃ‰SUMÃ‰:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "print(f\"\\nğŸ“Š DonnÃ©es analysÃ©es:\")\n",
    "print(f\"  - {train_df.shape[0]:,} commentaires d'entraÃ®nement\")\n",
    "print(f\"  - {test_df.shape[0]:,} commentaires de test\")\n",
    "print(f\"  - {len(found_personal_columns)} types de donnÃ©es personnelles ajoutÃ©es\")\n",
    "print(f\"  - {len(entities)} entitÃ©s dÃ©tectÃ©es par spaCy\")\n",
    "\n",
    "print(f\"\\nğŸ¯ Prochaines Ã©tapes:\")\n",
    "print(f\"  1. CrÃ©er le script d'anonymisation (scripts/anonymize.py)\")\n",
    "print(f\"  2. Traiter les donnÃ©es avec spaCy NER\")\n",
    "print(f\"  3. Appliquer les patterns regex\")\n",
    "print(f\"  4. Sauvegarder les versions anonymisÃ©es\")\n",
    "print(f\"  5. CrÃ©er le rapport de comparaison avant/aprÃ¨s\")\n",
    "\n",
    "print(f\"\\nğŸ›¡ï¸ PrioritÃ© RGPD: Ã‰LEVÃ‰E\")\n",
    "print(f\"  âš ï¸  Anonymisation obligatoire avant utilisation du modÃ¨le IA\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
